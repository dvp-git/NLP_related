{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate PyTorch: Building architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every neural net requires the `init` method and the `forward` method. \n",
    "`init` : Define the kinds of layers from PyTorch you want to utilize\n",
    "`forward` : Define the input feature matrix interaction with the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Predicting the output\n",
    "        pred = self.forward(x)\n",
    "        return pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        # Get the weights\n",
    "        return self.fc1.weight, self.fc2.weight\n",
    "\n",
    "    def get_bias(self):\n",
    "        # Get the bias\n",
    "        return self.fc1.bias, self.fc2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preventing Exploding Gradients and Vanishing Gradients \n",
    " - Use Batch Normalization : During training, we normalize the values of each layer neuron\n",
    " - Use elu instead of relu to prevent non-zero gradients for 0 valued outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Batch norm\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.bn1 = nn.BatchNorm1d(5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Networks for images.\n",
    "Why not linear layers ? Considering a single image as rowPixel x colPixel. 256 * 256 = ..some big number. Passed through this layer can cause large computation time for gradient updates and processing power as well.\n",
    "\n",
    "Convolution makes use of a filter which is moved over the original image to extract it's feature map. Padding of 0 on the border of image is done to maintain spatial dimension and avoid information loss.\n",
    "\n",
    "Usual process :\n",
    "\n",
    "Image --> Convolution --> Activation --> MaxPooling( to reduce dimension ) --> Convolution --> Activation --> MaxPooling( to reduce dimension ) --> Fully Connected Linear layer\n",
    "\n",
    "- `Convolution` : Changes number of output channels\n",
    "- `MaxPool`     : Reduces the size of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution_nn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_map = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) ,# 3 input channels, 32 output channels, 3x3 kernel\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),)\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes) # 64*8*8 is the number of features extracted by the convolutional layers\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # Pass input interactions\n",
    "        x = self.feature_map(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: Transforms you can use on a datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(35),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64,64)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics in torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchmetrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Precision, Recall\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
