{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate PyTorch: Building architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every neural net requires the `init` method and the `forward` method. \n",
    "`init` : Define the kinds of layers from PyTorch you want to utilize\n",
    "`forward` : Define the input feature matrix interaction with the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Predicting the output\n",
    "        pred = self.forward(x)\n",
    "        return pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        # Get the weights\n",
    "        return self.fc1.weight, self.fc2.weight\n",
    "\n",
    "    def get_bias(self):\n",
    "        # Get the bias\n",
    "        return self.fc1.bias, self.fc2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preventing Exploding Gradients and Vanishing Gradients \n",
    " - Use Batch Normalization : During training, we normalize the values of each layer neuron\n",
    " - Use elu instead of relu to prevent non-zero gradients for 0 valued outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Batch norm\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.bn1 = nn.BatchNorm1d(5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Networks for images.\n",
    "Why not linear layers ? Considering a single image as rowPixel x colPixel. 256 * 256 = ..some big number. Passed through this layer can cause large computation time for gradient updates and processing power as well.\n",
    "\n",
    "Convolution makes use of a filter which is moved over the original image to extract it's feature map. Padding of 0 on the border of image is done to maintain spatial dimension and avoid information loss.\n",
    "\n",
    "Usual process :\n",
    "\n",
    "Image --> Convolution --> Activation --> MaxPooling( to reduce dimension ) --> Convolution --> Activation --> MaxPooling( to reduce dimension ) --> Fully Connected Linear layer\n",
    "\n",
    "- `Convolution` : Changes number of output channels\n",
    "- `MaxPool`     : Reduces the size of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution_nn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_map = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) ,# 3 input channels, 32 output channels, 3x3 kernel\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),)\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes) # 64*8*8 is the number of features extracted by the convolutional layers\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # Pass input interactions\n",
    "        x = self.feature_map(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: Transforms you can use on a datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(35),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64,64)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics in torchmetrics\n",
    "\n",
    "Precision measures the accuracy of positive predictions. The formula is:\n",
    "\n",
    "\n",
    "$Precision = \\frac{True Positives (TP)}{True Positives (TP) + False Positives (FP)}$\n",
    "\n",
    "\n",
    "Recall measures the ability of a model to find all the relevant cases (true positives). The formula is:\n",
    "\n",
    "\n",
    "$Recall = \\frac{True Positives (TP)}{True Positives (TP) + False Negatives (FN)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Precision, Recall\n",
    "\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model : Recurrent Neural Network\n",
    "For time series, Genrative models, etc\n",
    "Hidden layer of previous layer passed as input to next layer as well.\n",
    "### Deep RNN , stacking multiple layers is also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic RNN Model\n",
    "class Rnn_(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=10, hidden_size=5, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 5)\n",
    "        out_, _ = self.rnn(x, h0)\n",
    "        out_ = self.linear(out_[:, -1, :])\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN is short term memory. For long term memory LSTM and GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic LSTM Model\n",
    "class Lstm_(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=10, hidden_size=5, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 5)\n",
    "        c0 = torch.zeros(2, x.size(0), 5)\n",
    "        out_, _ = self.lstm(x, (h0, c0))\n",
    "        out_ = self.linear(out_[:, -1, :])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic GRU Model\n",
    "class Gru_(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=10, hidden_size=5, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 5)\n",
    "        out_, _ = self.gru(x, h0)\n",
    "        out_ = self.linear(out_[:, -1, :])\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For time series data, the input to the model is expected in (batch, seq_len, features) format.\n",
    "# Accordingly change training loop / eval loop as follows:\n",
    "for epoch in range(num_epoch):\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x = x.permute(0, 2, 1) # permute the input to (batch, seq_len, features)\n",
    "        # rest of the training loop\n",
    "        # ...\n",
    "        # ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Input, Multiple output models\n",
    "\n",
    "- Multi input, Single Ouput : Image , text as input with the classified label as output\n",
    "- Single input, Multiple Output : Image used to provide information on multiple objects in the image.\n",
    "- Regularization : Take outputs at each NN and pass it for further learning of representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-input, Single Output \n",
    "# Note : If Single-input, Multi-output, then use 2 classifer layers in init and return 2 outputs in forward\n",
    "class Net_(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_layer = nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),   # 3 input channels, 32 output channels, 3x3 kernel\n",
    "                                        nn.ELU(),\n",
    "                                        nn.MaxPool2d(kernel_size=2),               \n",
    "                                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # 32 input channels, 64 output channels, 3x3 kernel\n",
    "                                        nn.ELU(),\n",
    "                                        nn.MaxPool2d(kernel_size=2),\n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(64*16*16, 128))                 # 64*16*16 is the number of features extracted by the convolutional layers\n",
    "        self.text_layer = nn.Sequential(nn.Linear(10, 5),nn.ELU())                  # 10 input features, 5 output features  \n",
    "        self.classifier = nn.Sequential(nn.Linear(128+5, 1000))                       # 128+5 is the number of features from both, 1000 is number of classes     \n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img = self.img_layer(img)\n",
    "        text = self.text_layer(text)\n",
    "        x = torch.cat((img, text), dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
