{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate PyTorch: Building architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every neural net requires the `init` method and the `forward` method. \n",
    "`init` : Define the kinds of layers from PyTorch you want to utilize\n",
    "`forward` : Define the input feature matrix interaction with the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Predicting the output\n",
    "        pred = self.forward(x)\n",
    "        return pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        # Get the weights\n",
    "        return self.fc1.weight, self.fc2.weight\n",
    "\n",
    "    def get_bias(self):\n",
    "        # Get the bias\n",
    "        return self.fc1.bias, self.fc2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preventing Exploding Gradients and Vanishing Gradients \n",
    " - Use Batch Normalization : During training, we normalize the values of each layer neuron\n",
    " - Use elu instead of relu to prevent non-zero gradients for 0 valued outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Batch norm\n",
    "class CustomNet(nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    ## Copilot recommended\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.bn1 = nn.BatchNorm1d(5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x): # Defines the computation performed at every call , every neuron\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
