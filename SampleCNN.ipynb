{"cells":[{"cell_type":"markdown","id":"5e7e68d5","metadata":{},"source":["### Sample CNN "]},{"attachments":{},"cell_type":"markdown","id":"35d4e17b-eeb6-40dd-a140-7b949390e115","metadata":{"tags":[]},"source":["Fashion Forward is a new AI-based e-commerce clothing retailer.\n","They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n","\n","As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."]},{"cell_type":"code","execution_count":70,"id":"4de0b0ff-a211-41be-b90e-165e6038c9d7","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":5273,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1709429151931,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.3.1)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>17.1->torchmetrics) (3.0.9)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":71,"id":"145bbc0f-4d15-4e7b-b796-5ec0d9ab7702","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1709429151981,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics import Accuracy, Precision, Recall"]},{"cell_type":"code","execution_count":72,"id":"35ddad8f-fa43-4bb3-894b-afef8d0bfd59","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":63,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1709429152044,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":77,"type":"stream"},"2":{"height":117,"type":"stream"},"4":{"height":117,"type":"stream"},"6":{"height":117,"type":"stream"},"8":{"height":57,"type":"stream"}}},"outputs":[],"source":["# Load datasets\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"code","execution_count":73,"id":"6ef2add2-b7e9-4527-8f19-9729bdc27ea4","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1709429152094,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(train_data[0][0].shape[0])\nprint(train_data[0][0].shape[-1])\nprint(train_data.targets)\nlen(torch.unique(train_data.targets))","outputsMetadata":{"0":{"height":77,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","28\n","tensor([9, 0, 0,  ..., 3, 0, 5])\n"]},{"data":{"text/plain":["10"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["print(train_data[0][0].shape[0])\n","print(train_data[0][0].shape[-1])\n","print(train_data.targets)\n","len(torch.unique(train_data.targets))"]},{"cell_type":"code","execution_count":74,"id":"e5d01322-e517-44b8-a68f-1ff0e291418f","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709429152145,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here\nIMAGE_SIZE = train_data[0][0].shape[-1]\nNUM_CLASSES = len(torch.unique(train_data.targets))\nIN_CHANNELS = train_data[0][0].shape[0]\n\n\n\n# Use as many cells as you need\nclass ConvNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels=IN_CHANNELS, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten_ = nn.Flatten()\n        self.linear = nn.Linear(8 * (IMAGE_SIZE// 2) * (IMAGE_SIZE//2), NUM_CLASSES)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten_(x)\n        x = self.linear(x)\n        return x"},"outputs":[],"source":["# Start coding here\n","IMAGE_SIZE = train_data[0][0].shape[-1]\n","NUM_CLASSES = len(torch.unique(train_data.targets))\n","IN_CHANNELS = train_data[0][0].shape[0]\n","\n","\n","\n","# Use as many cells as you need\n","class ConvNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels=IN_CHANNELS, out_channels=8, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.flatten_ = nn.Flatten()\n","        self.linear = nn.Linear(8 * (IMAGE_SIZE// 2) * (IMAGE_SIZE//2), NUM_CLASSES)\n","        \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.flatten_(x)\n","        x = self.linear(x)\n","        return x"]},{"cell_type":"code","execution_count":75,"id":"1e8a15d1-140d-40d8-a5d4-cd598563fbdf","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709429152197,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"train_data_loader = DataLoader(train_data, batch_size=10 , shuffle=True)\ntest_data_loader = DataLoader(test_data, batch_size=10, shuffle=True)\nmodel = ConvNN()"},"outputs":[],"source":["train_data_loader = DataLoader(train_data, batch_size=10 , shuffle=True)\n","test_data_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n","model = ConvNN()"]},{"cell_type":"code","execution_count":76,"id":"a7e1b254-6d33-4b3a-b135-0d90526327c7","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709429152249,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"optimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef train_model(data_loader, optimizer, epochs, lr , model):\n    for epoch in range(1,epochs):\n        epoch_loss = 0\n        num_processed = 0\n        for data in data_loader:\n            optimizer.zero_grad()\n            features, targets = data[0], data[1]\n            output = model(features)\n            loss = criterion(output, targets)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            num_processed += len(targets)\n        print(f\"Epoch {epoch} Loss :  {epoch_loss / num_processed}\")\n    train_loss = epoch_loss / len(data_loader)\n    print(\"Final Train loss:\",train_loss)","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","def train_model(data_loader, optimizer, epochs, lr , model):\n","    for epoch in range(1,epochs):\n","        epoch_loss = 0\n","        num_processed = 0\n","        for data in data_loader:\n","            optimizer.zero_grad()\n","            features, targets = data[0], data[1]\n","            output = model(features)\n","            loss = criterion(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","            num_processed += len(targets)\n","        print(f\"Epoch {epoch} Loss :  {epoch_loss / num_processed}\")\n","    train_loss = epoch_loss / len(data_loader)\n","    print(\"Final Train loss:\",train_loss)"]},{"cell_type":"code","execution_count":77,"id":"ce7db978-bdb2-4f74-89c2-5ec0720ee2a5","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":77,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Loss :  0.043536890305446774\n","Epoch 2 Loss :  0.032037951028265524\n","Final Train loss: 0.32037951028265527\n"]}],"source":["train_model(train_data_loader, optimizer, 3, 0.001, model)"]},{"cell_type":"code","execution_count":78,"id":"60cf001e-e27f-4d83-91f9-1ed5f05ce264","metadata":{"executionCancelledAt":null,"executionTime":76,"lastExecutedAt":1709429220580,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"accuracy_metric = Accuracy(task='multiclass', num_classes=NUM_CLASSES)\nprecision_metric = Precision(task='multiclass', num_classes=NUM_CLASSES, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=NUM_CLASSES, average=None)\npredictions = []\n\ndef eval_model(data_loader, epochs, model):\n    model.eval()\n    with torch.no_grad():\n        for data in data_loader:\n            features, targets = data[0], data[1]\n            output = model(features)\n            predicted = torch.argmax(output,dim=-1)\n            predictions.extend(predicted)\n            accuracy_metric(predicted,targets)\n            precision_metric(predicted,targets)\n            recall_metric(predicted,targets)"},"outputs":[],"source":["accuracy_metric = Accuracy(task='multiclass', num_classes=NUM_CLASSES)\n","precision_metric = Precision(task='multiclass', num_classes=NUM_CLASSES, average=None)\n","recall_metric = Recall(task='multiclass', num_classes=NUM_CLASSES, average=None)\n","predictions = []\n","\n","def eval_model(data_loader, epochs, model):\n","    model.eval()\n","    with torch.no_grad():\n","        for data in data_loader:\n","            features, targets = data[0], data[1]\n","            output = model(features)\n","            predicted = torch.argmax(output,dim=-1)\n","            predictions.extend(predicted)\n","            accuracy_metric(predicted,targets)\n","            precision_metric(predicted,targets)\n","            recall_metric(predicted,targets)"]},{"cell_type":"code","execution_count":79,"id":"7c9b667a-d616-4acc-879a-dc0031149f0f","metadata":{"executionCancelledAt":null,"executionTime":9894,"lastExecutedAt":1709429230474,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"eval_model(test_data_loader, 3, model)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[],"source":["eval_model(test_data_loader, 3, model)"]},{"cell_type":"code","execution_count":80,"id":"a3a86410-3264-4f69-968a-00ae820c23dc","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1709429230525,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"accuracy = accuracy_metric.compute()\nprecision = precision_metric.compute()\nrecall = recall_metric.compute()\n\n\nprint(\"Accuracy\", accuracy)\nprint(\"Precision\", precision)\nprint(\"Recall\", recall)","outputsMetadata":{"0":{"height":117,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy tensor(0.8833)\n","Precision tensor([0.8442, 0.9887, 0.7921, 0.8814, 0.7898, 0.9866, 0.6877, 0.9167, 0.9739,\n","        0.9742])\n","Recall tensor([0.8020, 0.9650, 0.8460, 0.8920, 0.8490, 0.9540, 0.6320, 0.9790, 0.9710,\n","        0.9430])\n"]}],"source":["accuracy = accuracy_metric.compute()\n","precision = precision_metric.compute()\n","recall = recall_metric.compute()\n","\n","\n","print(\"Accuracy\", accuracy)\n","print(\"Precision\", precision)\n","print(\"Recall\", recall)"]},{"cell_type":"code","execution_count":81,"id":"735b2552-6314-442e-96a1-e4d495a832b7","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1709429289229,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"outputs":[],"source":[]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
